{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载IDRR_data的dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IDRR_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'/data/whsun/idrr/data/raw/pdtb2.p1.csv'\n",
    "df = IDRRDataFrames(\n",
    "    data_name='pdtb2',\n",
    "    data_level='top',\n",
    "    data_relation='Implicit',\n",
    "    data_path=data_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg2</th>\n",
       "      <th>conn1</th>\n",
       "      <th>conn2</th>\n",
       "      <th>conn1sense1</th>\n",
       "      <th>conn1sense2</th>\n",
       "      <th>conn2sense1</th>\n",
       "      <th>conn2sense2</th>\n",
       "      <th>relation</th>\n",
       "      <th>split</th>\n",
       "      <th>...</th>\n",
       "      <th>label12</th>\n",
       "      <th>label12id</th>\n",
       "      <th>label21</th>\n",
       "      <th>label21id</th>\n",
       "      <th>label22</th>\n",
       "      <th>label22id</th>\n",
       "      <th>ans_word1</th>\n",
       "      <th>ans_word1id</th>\n",
       "      <th>ans_word2</th>\n",
       "      <th>ans_word2id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>In an Oct. 19 review of \"The Misanthrope\" at C...</td>\n",
       "      <td>Ms. Haag plays Elianti</td>\n",
       "      <td>however</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comparison.Contrast.Juxtaposition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>however</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>BELL INDUSTRIES Inc. increased its quarterly t...</td>\n",
       "      <td>The new rate will be payable Feb. 15</td>\n",
       "      <td>and</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expansion.Conjunction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>and</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>The new rate will be payable Feb. 15</td>\n",
       "      <td>A record date hasn't been set</td>\n",
       "      <td>however</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comparison.Contrast.Juxtaposition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>however</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>Solo woodwind players have to be creative if t...</td>\n",
       "      <td>The oboist Heinz Holliger has taken a hard lin...</td>\n",
       "      <td>for example</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expansion.Instantiation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>instance</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>Richard Stoltzman has taken a gentler, more au...</td>\n",
       "      <td>Years ago, he collaborated with the new music ...</td>\n",
       "      <td>although</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expansion.Restatement.Specification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>although</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13810</th>\n",
       "      <td>Exports declined for the second month in a row...</td>\n",
       "      <td>An analyst called it one of the worst trade re...</td>\n",
       "      <td>in fact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expansion.Conjunction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>and</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13811</th>\n",
       "      <td>Industrial output fell 0.1% in September, the ...</td>\n",
       "      <td>weaker capital spending and exports</td>\n",
       "      <td>because</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contingency.Cause.Reason</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>because</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13812</th>\n",
       "      <td>Three big drug makers posted robust third-quar...</td>\n",
       "      <td>Merck's profit climbed 25%, Warner-Lambert's 2...</td>\n",
       "      <td>specifically</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expansion.Restatement.Specification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>specifically</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13813</th>\n",
       "      <td>The B/T gene rearrangement test is more accura...</td>\n",
       "      <td>the test initially will be used in conjunction...</td>\n",
       "      <td>so</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contingency.Cause.Result</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>so</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13814</th>\n",
       "      <td>the test is widely used in research centers bu...</td>\n",
       "      <td>We don't know yet how useful it's going to be</td>\n",
       "      <td>so</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contingency.Cause.Result</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>train</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>so</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12632 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    arg1  \\\n",
       "1183   In an Oct. 19 review of \"The Misanthrope\" at C...   \n",
       "1184   BELL INDUSTRIES Inc. increased its quarterly t...   \n",
       "1185                The new rate will be payable Feb. 15   \n",
       "1186   Solo woodwind players have to be creative if t...   \n",
       "1187   Richard Stoltzman has taken a gentler, more au...   \n",
       "...                                                  ...   \n",
       "13810  Exports declined for the second month in a row...   \n",
       "13811  Industrial output fell 0.1% in September, the ...   \n",
       "13812  Three big drug makers posted robust third-quar...   \n",
       "13813  The B/T gene rearrangement test is more accura...   \n",
       "13814  the test is widely used in research centers bu...   \n",
       "\n",
       "                                                    arg2         conn1 conn2  \\\n",
       "1183                              Ms. Haag plays Elianti       however   NaN   \n",
       "1184                The new rate will be payable Feb. 15           and   NaN   \n",
       "1185                       A record date hasn't been set       however   NaN   \n",
       "1186   The oboist Heinz Holliger has taken a hard lin...   for example   NaN   \n",
       "1187   Years ago, he collaborated with the new music ...      although   NaN   \n",
       "...                                                  ...           ...   ...   \n",
       "13810  An analyst called it one of the worst trade re...       in fact   NaN   \n",
       "13811                weaker capital spending and exports       because   NaN   \n",
       "13812  Merck's profit climbed 25%, Warner-Lambert's 2...  specifically   NaN   \n",
       "13813  the test initially will be used in conjunction...            so   NaN   \n",
       "13814      We don't know yet how useful it's going to be            so   NaN   \n",
       "\n",
       "                               conn1sense1 conn1sense2 conn2sense1  \\\n",
       "1183     Comparison.Contrast.Juxtaposition         NaN         NaN   \n",
       "1184                 Expansion.Conjunction         NaN         NaN   \n",
       "1185     Comparison.Contrast.Juxtaposition         NaN         NaN   \n",
       "1186               Expansion.Instantiation         NaN         NaN   \n",
       "1187   Expansion.Restatement.Specification         NaN         NaN   \n",
       "...                                    ...         ...         ...   \n",
       "13810                Expansion.Conjunction         NaN         NaN   \n",
       "13811             Contingency.Cause.Reason         NaN         NaN   \n",
       "13812  Expansion.Restatement.Specification         NaN         NaN   \n",
       "13813             Contingency.Cause.Result         NaN         NaN   \n",
       "13814             Contingency.Cause.Result         NaN         NaN   \n",
       "\n",
       "      conn2sense2  relation  split  ...  label12  label12id label21  \\\n",
       "1183          NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "1184          NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "1185          NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "1186          NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "1187          NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "...           ...       ...    ...  ...      ...        ...     ...   \n",
       "13810         NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "13811         NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "13812         NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "13813         NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "13814         NaN  Implicit  train  ...     <NA>       <NA>    <NA>   \n",
       "\n",
       "       label21id label22 label22id     ans_word1 ans_word1id ans_word2  \\\n",
       "1183        <NA>    <NA>      <NA>       however           3      <NA>   \n",
       "1184        <NA>    <NA>      <NA>           and          11      <NA>   \n",
       "1185        <NA>    <NA>      <NA>       however           3      <NA>   \n",
       "1186        <NA>    <NA>      <NA>      instance          13      <NA>   \n",
       "1187        <NA>    <NA>      <NA>      although           0      <NA>   \n",
       "...          ...     ...       ...           ...         ...       ...   \n",
       "13810       <NA>    <NA>      <NA>           and          11      <NA>   \n",
       "13811       <NA>    <NA>      <NA>       because           4      <NA>   \n",
       "13812       <NA>    <NA>      <NA>  specifically          15      <NA>   \n",
       "13813       <NA>    <NA>      <NA>            so           5      <NA>   \n",
       "13814       <NA>    <NA>      <NA>            so           5      <NA>   \n",
       "\n",
       "      ans_word2id  \n",
       "1183         <NA>  \n",
       "1184         <NA>  \n",
       "1185         <NA>  \n",
       "1186         <NA>  \n",
       "1187         <NA>  \n",
       "...           ...  \n",
       "13810        <NA>  \n",
       "13811        <NA>  \n",
       "13812        <NA>  \n",
       "13813        <NA>  \n",
       "13814        <NA>  \n",
       "\n",
       "[12632 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(df.train_df['label11'])\n",
    "def write_jsonl(file, data):\n",
    "    with open(file, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "def read_jsonl(file_path):\n",
    "    import json\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "def write_json(file, data):\n",
    "    import json\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Data saved to {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parquet格式化数据 (以qwen3为例)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdtb2_top_Implicit"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IDRR_data import IDRRDataFrames\n",
    "df = IDRRDataFrames(\n",
    "    data_name='pdtb2',\n",
    "    data_level='top',\n",
    "    data_relation='Implicit',\n",
    "    data_path=r'/data/whsun/idrr/data/raw/pdtb2.p1.csv',\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Task\\nYou are an expert in the field of implicit discourse relations. Your task is to determine the semantic-logical relationship between two given text segments and select the most appropriate relation label. Output only one of A, B, C, or D, and enclose it in \\\\boxed{{}}.\\n\\n### Relations\\n{relation_terms}\\n\\n### Segments\\nText segment 1: {arg1}\\nText segment 2: {arg2}\\n\\nYour answer:\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = read_txt(\"/data/whsun/idrr/prompts/rl_base.txt\")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source': 'pdtb',\n",
       " 'prompt': [{'content': '<｜begin▁of▁sentence｜><｜User｜>### Task\\nYou are an expert in the field of implicit discourse relations. Your task is to determine the semantic-logical relationship between two given text segments and select the most appropriate relation label. Output only one of A, B, C, or D, and enclose it in \\\\boxed{}.\\n\\n### Relations\\nA. Comparison\\nB. Contingency\\nC. Expansion\\nD. Temporal\\n\\n### Segments\\nText segment 1: In an Oct. 19 review of \"The Misanthrope\" at Chicago\\'s Goodman Theatre (\"Revitalized Classics Take the Stage in Windy City,\" Leisure & Arts), the role of Celimene, played by Kim Cattrall, was mistakenly attributed to Christina Haag\\nText segment 2: Ms. Haag plays Elianti\\n\\nYour answer:\\n',\n",
       "   'role': 'user'}],\n",
       " 'reward_model': {'ground_truth': 'A'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/whsun/pretrained_models/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "\n",
    "def get_rl_data(data_source: str, df, label_list):\n",
    "    rl_data = []\n",
    "    relation_terms = '\\n'.join([f\"{chr(65 + i)}. {label}\" for i, label in enumerate(label_list)])\n",
    "    label2alpha = {label: chr(65 + i) for i, label in enumerate(label_list)}\n",
    "    for index, row in df.iterrows():\n",
    "        prompt = prompt_template.format(\n",
    "            relation_terms=relation_terms,\n",
    "            arg1=row['arg1'],\n",
    "            arg2=row['arg2'],\n",
    "        )\n",
    "        grounth_truth_alpha = label2alpha[row[\"label11\"]]\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "\n",
    "        rl_data.append(\n",
    "            {\n",
    "                \"data_source\": data_source,\n",
    "                \"prompt\": [{\"content\": prompt_text, \"role\": \"user\"}],\n",
    "                \"reward_model\": {\"ground_truth\": grounth_truth_alpha},\n",
    "            }\n",
    "        )\n",
    "    return Dataset.from_list(rl_data, split=\"train\")\n",
    "\n",
    "train_rl_dataset = get_rl_data(\"pdtb\", df.train_df, df.label_list)\n",
    "train_rl_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['data_source', 'prompt', 'reward_model'],\n",
       "     num_rows: 1183\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['data_source', 'prompt', 'reward_model'],\n",
       "     num_rows: 1046\n",
       " }))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rl_dataset = get_rl_data(\"pdtb\", df.dev_df, df.label_list)\n",
    "test_rl_dataset = get_rl_data(\"pdtb\", df.test_df, df.label_list)\n",
    "dev_rl_dataset, test_rl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 13/13 [00:00<00:00, 512.68ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 949.80ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "703089"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/train.parquet\")\n",
    "# dev_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/dev.parquet\")\n",
    "test_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将label转化为关系定义进行sft\n",
    "1. 将二级label转为关系定义\n",
    "2. 模型1：论元对 -> 关系定义\n",
    "3. 模型2：模型1给出文本 -> label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Briefly describe the relationship between two arguments and output the final relation label.\\nArg1: {arg1}\\nArg2: {arg2}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tmeplate = read_txt(\"/data/sunwh/idrr/prompts/arg2def.txt\")\n",
    "prompt_tmeplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /data/sunwh/idrr/data/arg2def/pdtb2/aplaca/train.json\n",
      "Data saved to /data/sunwh/idrr/data/arg2def/pdtb2/aplaca/test.json\n",
      "Data saved to /data/sunwh/idrr/data/arg2def/pdtb2/aplaca/dev.json\n"
     ]
    }
   ],
   "source": [
    "sense2df = {\n",
    "    \"Temporal\": \"The situations described in the arguments are related temporally.\",\n",
    "    \"Temporal.Asynchronous\": \"One envent is described as preceding the other.\",\n",
    "    \"Temporal.Synchrony\": \"There is some degree of temporal overlap between the events described by the arguments.\",\n",
    "    \"Contingency\": \"One of the situations described in Arg1 and Arg2 causally influences the other.\",\n",
    "    \"Contingency.Cause\":\"The situations described in the arguments are causally influenced and the two are not in a conditional relation.\",\n",
    "    \"Contingency.Pragmatic cause\":\"Arg1 expresses a claim and Arg2 provides justification for this claim.\",\n",
    "    \"Contingency.Condition\": \"The situation in Arg2 is taken to be the condition and the situation described in Arg1 is taken to be the consequence.\",\n",
    "    \"Contingency.Pragmatic condition\": \"Used for instances of conditional constructions whose interpretation deviates from that of the semantics of “Condition”.\",\n",
    "    \"Comparison\": \"A discourse relation is established between Arg1 and Arg2 in order to highlight prominent differences between the two situations.\",\n",
    "    \"Comparison.Contrast\": \"Arg1 and Arg2 share a predicate or property and a difference is highlighted with respect to the values assigned to the shared property.\",\n",
    "    \"Comparison.Pragmatic contrast\": \"A contrast between one of the arguments and an inference that can be drawn from the other, in many cases at the speech act level: The contrast is not between the situations described in Arg1 and Arg2.\",\n",
    "    \"Comparison.Concession\": \"One argument denotes a fact that triggers a set of potential consequences, while the other denies one or more of them.\",\n",
    "    \"Comparison.Pragmatic concession\": \"One argument denotes a fact that triggers a set of potential consequences, while the other denies one or more of them. The denial is not at the level of the situations described in Arg1 and Arg2, but rather at the level of inferences that can be drawn from them.\",\n",
    "    \"Expansion\": \"Expanding the discourse and move its narrative or exposition forward.\",\n",
    "    \"Expansion.Conjunction\":\"The situation described in Arg2 provides additional, discourse new, information that is related to the situation described in Arg1, but is not related to Arg1 in any of the ways described for other types of “EXPANSION”.\",\n",
    "    \"Expansion.Instantiation\":\"Arg1 evokes a set and Arg2 describes it in further detail, It may be a set of events, a set of reasons, or a generic set of events, behaviors, attitudes, etc.\",\n",
    "    \"Expansion.Restatement\":\"The semantics of Arg2 restates the semantics of Arg1. It is inferred that the situations described in Arg1 and Arg2 hold true at the same time.\",\n",
    "    \"Expansion.Alternative\":\"Two arguments denote alternative situations.\",\n",
    "    \"Expansion.Exception\":\"Arg2 specifies an exception to the generalization specified by Arg1. In other words, Arg1 is false because Arg2 is true, but if Arg2 were false, Arg1 would be true.\",\n",
    "    \"Expansion.List\":\"Arguments are members of a list, defined in the prior discourse.“List”does not require the situations specified in Arg1 and Arg2 to be directly related.\"\n",
    "}\n",
    "def write_json(file, data):\n",
    "    import json\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Data saved to {file}\")\n",
    "\n",
    "def write_alpaca_format(df, file_path):\n",
    "    alpaca_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = prompt_tmeplate.format(\n",
    "            arg1=row['arg1'],\n",
    "            arg2=row['arg2'],\n",
    "        )\n",
    "        sense = row['conn1sense1']\n",
    "        sense_lst = sense.split('.')\n",
    "        if len(sense_lst) > 1:\n",
    "            sense = '.'.join(sense_lst[:2])\n",
    "        alpaca_data.append(\n",
    "            {\n",
    "                \"instruction\": prompt,\n",
    "                \"input\": \"\",\n",
    "                \"output\": sense2df[sense] + f' Relation: {sense}' if len(df) > 9999 else sense,\n",
    "            }\n",
    "        )\n",
    "    write_json(file_path, alpaca_data)\n",
    "\n",
    "write_alpaca_format(df.train_df, \"/data/sunwh/idrr/data/arg2def/pdtb2/aplaca/train.json\")\n",
    "write_alpaca_format(df.test_df, \"/data/sunwh/idrr/data/arg2def/pdtb2/aplaca/test.json\")\n",
    "write_alpaca_format(df.dev_df, \"/data/sunwh/idrr/data/arg2def/pdtb2/aplaca/dev.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将easyr1的jsonl文件转为parquet格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source': 'pdtb',\n",
       " 'prompt': [{'content': '<|im_start|>user\\n# Instruction\\nYou are an expert in the field of implicit discourse relation recognition. Your task is to analyze the implicit logical relation between two adjacent text segments and choose the most accurate relation from the options.\\n\\n# Input\\nSegment 1: In an Oct. 19 review of \"The Misanthrope\" at Chicago\\'s Goodman Theatre (\"Revitalized Classics Take the Stage in Windy City,\" Leisure & Arts), the role of Celimene, played by Kim Cattrall, was mistakenly attributed to Christina Haag\\nSegment 2: Ms. Haag plays Elianti\\nRelation option:\\nA. Comparison\\nB. Contingency\\nC. Expansion\\nD. Temporal<|im_end|>\\n<|im_start|>assistant\\n',\n",
       "   'role': 'user'}],\n",
       " 'reward_model': {'ground_truth': 'A'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def write_rl_dataset(data_path):\n",
    "    data = read_jsonl(data_path)\n",
    "    rl_data = []\n",
    "    # data格式为problem, answer\n",
    "    from transformers import AutoTokenizer\n",
    "    from datasets import Dataset\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"/data/whsun/pretrained_models/Qwen/Qwen3-0.6B\")\n",
    "    data_source = \"pdtb\"\n",
    "    for item in data:\n",
    "        prompt_text = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": item['problem']}],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "        grounth_truth_alpha = item['answer'].strip()\n",
    "        rl_data.append(\n",
    "            {\n",
    "                \"data_source\": data_source,\n",
    "                \"prompt\": [{\"content\": prompt_text, \"role\": \"user\"}],\n",
    "                \"reward_model\": {\"ground_truth\": grounth_truth_alpha},\n",
    "            }\n",
    "        )\n",
    "    return Dataset.from_list(rl_data, split=\"train\")\n",
    "\n",
    "train_rl_dataset = write_rl_dataset(\"/data/whsun/idrr/data/rl/easyr1/pdtb2/top/sft_rl_train.jsonl\")\n",
    "test_rl_dataset = write_rl_dataset(\"/data/whsun/idrr/data/rl/easyr1/pdtb2/top/sft_rl_test.jsonl\")\n",
    "train_rl_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 13/13 [00:00<00:00, 86.21ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 645.72ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "640329"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/sft_rl_train.parquet\")\n",
    "test_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/sft_rl_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将parquet数据转成json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成！输出文件: /data/whsun/idrr/data/rl/verl/pdtb2/top/distill_qwen_1.5b_gen_test.json\n",
      "数据形状: (1046, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def parquet_to_json_pandas(input_file, output_file, orient='records', indent=2):\n",
    "    \"\"\"\n",
    "    使用pandas将Parquet转换为JSON\n",
    "    \n",
    "    参数:\n",
    "        input_file: 输入的Parquet文件路径\n",
    "        output_file: 输出的JSON文件路径\n",
    "        orient: JSON格式（'records'为行记录，'split'为分离格式等）\n",
    "        indent: JSON缩进，None为压缩格式，数字为缩进空格数\n",
    "    \"\"\"\n",
    "    # 读取Parquet文件\n",
    "    df = pd.read_parquet(input_file)\n",
    "    \n",
    "    # 转换为JSON字符串\n",
    "    json_str = df.to_json(orient=orient, indent=indent, force_ascii=False)\n",
    "    \n",
    "    # 写入文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json_str)\n",
    "    \n",
    "    print(f\"转换完成！输出文件: {output_file}\")\n",
    "    print(f\"数据形状: {df.shape}\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    parquet_to_json_pandas('/data/whsun/idrr/data/rl/verl/pdtb2/top/distill_qwen_1.5b_gen_test.parquet', '/data/whsun/idrr/data/rl/verl/pdtb2/top/distill_qwen_1.5b_gen_test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据lmf输出构造alpaca训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9485/12632 = 0.7509\n",
      "Total samples: 9485\n",
      "Correct samples: 9485\n",
      "Data saved to /data/whsun/idrr/data/sft/rl_cold_start/pdtb2/top/alpaca/qwen3-8b-exp-dapo_lora-distill_train.json\n"
     ]
    }
   ],
   "source": [
    "data = read_jsonl('/data/whsun/idrr/results/rl_cold_start/pdtb2/top/Qwen3-8B-E1_by_qwen3_max-DAPO-lora/global_step_210/train/generated_predictions.jsonl')\n",
    "new_data = []\n",
    "import re\n",
    "def re_search(text, type):\n",
    "    '''\n",
    "    搜索text中符合type类型的内容,\n",
    "    如果text中存在多个符合type类型的内容，则返回最后一个\n",
    "    如果搜索不到，则抛出异常\n",
    "    '''\n",
    "    pattern = ''\n",
    "    flags = re.DOTALL  # 添加 DOTALL 标志，让 . 也匹配换行符\n",
    "    \n",
    "    if type == 'json':\n",
    "        pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    elif type == 'box':\n",
    "        pattern = r'boxed{(.*?)}'\n",
    "    elif type == 'xml':\n",
    "        pattern = r'```xml\\s*(.*?)\\s*```'\n",
    "\n",
    "    matches = re.findall(pattern, text, flags)\n",
    "    if not matches and type == 'json':\n",
    "        # 使用贪婪匹配来匹配完整的字典结构\n",
    "        pattern = r'\\{.*\\}'\n",
    "        matches = re.findall(pattern, text, flags)\n",
    "\n",
    "    if len(matches) > 1:\n",
    "        logger.warning(f\"the number of matches is greater than 1:\")\n",
    "        for i, match in enumerate(matches):\n",
    "            logger.debug(f\"match{i}:\\n{match}\\n\")\n",
    "    elif not matches:\n",
    "        logger.error(f\"no matches found for {type} in text:\\n{text}\\n\")\n",
    "        raise ValueError()\n",
    "        return text\n",
    "\n",
    "    structured_text = matches[-1]\n",
    "    # if type == 'json':\n",
    "    #     structured_text = repair_json(structured_text)\n",
    "    return structured_text\n",
    "\n",
    "\n",
    "correct_cnt = 0\n",
    "for item in data:\n",
    "    pred = re_search(item['predict'], 'box')\n",
    "    label = re_search(item['label'], 'box')\n",
    "    # print(f\"Predicted: {pred}, Label: {label}\")\n",
    "    if pred == label:\n",
    "        correct_cnt += 1\n",
    "        new_data.append({\n",
    "                'instruction': item['prompt'].replace('\\nassistant\\n', '').replace('user\\n', ''),\n",
    "                'input': '',\n",
    "                'output': item['predict'],\n",
    "            })\n",
    "        \n",
    "print(f\"Accuracy: {correct_cnt}/{len(data)} = {correct_cnt/len(data):.4f}\")\n",
    "print(f\"Total samples: {len(new_data)}\")\n",
    "print(f\"Correct samples: {correct_cnt}\")\n",
    "write_json('/data/whsun/idrr/data/sft/rl_cold_start/pdtb2/top/alpaca/qwen3-8b-exp-dapo_lora-distill_train.json', new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API平台批量推理数据构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /data/whsun/idrr/data/api/volcengine/pdtb2/top/id2label.json\n"
     ]
    }
   ],
   "source": [
    "### 生成label\n",
    "data = {}\n",
    "cnt = 1\n",
    "label2alpha = {label: chr(65 + i) for i, label in enumerate(df.label_list)}\n",
    "for _, row in df.test_df.iterrows():\n",
    "    data[f\"request-{cnt}\"] = label2alpha[row['label11']]\n",
    "    cnt += 1\n",
    "\n",
    "write_json('/data/whsun/idrr/data/api/volcengine/pdtb2/top/id2label.json', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### volcengine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task\n",
      "You are an expert in the field of implicit discourse relations. Your task is to determine the semantic-logical relationship between two given text segments and select the most appropriate relation label. Output only one of A, B, C, or D, and enclose it in \\boxed{{}}.\n",
      "\n",
      "### Relations\n",
      "{relation_terms}\n",
      "\n",
      "### Segments\n",
      "Text segment 1: {arg1}\n",
      "Text segment 2: {arg2}\n",
      "\n",
      "Your answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "prompt_template = read_txt(\"/data/whsun/idrr/prompts/rl_base.txt\")\n",
    "print(prompt_template)\n",
    "# {\"custom_id\": \"request-1\", \"body\": {\"messages\": [{\"role\": \"user\", \"content\": \"天空为什么这么蓝？\"}],\"max_tokens\": 1000,\"top_p\":1,\"temperature\":0.7}}\n",
    "cnt = 1\n",
    "for _, row in df.test_df.iterrows():\n",
    "    data.append(\n",
    "        {\n",
    "            'custom_id': f\"request-{cnt}\",\n",
    "            'body': {\n",
    "                'reasoning_effort': 'high',\n",
    "                'messages': [\n",
    "                    {\n",
    "                    'role': 'user',\n",
    "                    'content': prompt_template.format(\n",
    "                        relation_terms='\\n'.join([f\"{chr(65 + i)}. {label}\" for i, label in enumerate(df.label_list)]),\n",
    "                        arg1=row['arg1'],\n",
    "                        arg2=row['arg2'],\n",
    "                    )\n",
    "                    }\n",
    "                ],\n",
    "                'max_tokens': 2048,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    cnt += 1\n",
    "\n",
    "write_jsonl('/data/whsun/idrr/data/api/volcengine/pdtb2/top/test.jsonl', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 阿里云"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task\n",
      "You are an expert in the field of implicit discourse relations. Your task is to determine the semantic-logical relationship between two given text segments and select the most appropriate relation label. Output only one of A, B, C, or D, and enclose it in \\boxed{{}}.\n",
      "\n",
      "### Relations\n",
      "{relation_terms}\n",
      "\n",
      "### Segments\n",
      "Text segment 1: {arg1}\n",
      "Text segment 2: {arg2}\n",
      "\n",
      "Your answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "prompt_template = read_txt(\"/data/whsun/idrr/prompts/rl_base.txt\")\n",
    "print(prompt_template)\n",
    "# {\"custom_id\": \"request-1\", \"body\": {\"messages\": [{\"role\": \"user\", \"content\": \"天空为什么这么蓝？\"}],\"max_tokens\": 1000,\"top_p\":1,\"temperature\":0.7}}\n",
    "cnt = 1\n",
    "for _, row in df.test_df.iterrows():\n",
    "    data.append(\n",
    "        {\n",
    "            'custom_id': f\"request-{cnt}\",\n",
    "            'method': 'POST',\n",
    "            'url': '/v1/chat/completions',\n",
    "            'body': {\n",
    "                'model': 'deepseek-v3.2',\n",
    "                'messages': [\n",
    "                    {\n",
    "                        'role': 'user',\n",
    "                        'content': prompt_template.format(\n",
    "                            relation_terms='\\n'.join([f\"{chr(65 + i)}. {label}\" for i, label in enumerate(df.label_list)]),\n",
    "                            arg1=row['arg1'],\n",
    "                            arg2=row['arg2'],\n",
    "                        )\n",
    "                    }\n",
    "                ],\n",
    "                'extra_body': {'enable_thinking': True},\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    cnt += 1\n",
    "\n",
    "write_jsonl('/data/whsun/idrr/data/api/aliyun/pdtb2/top/ds_v3_2_think_test.jsonl', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
