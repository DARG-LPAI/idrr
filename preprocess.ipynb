{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载IDRR_data的dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "def read_file(data_path: str) -> list | dict:\n",
    "    \"\"\"Read data from txt or json or jsonl or yaml file.\"\"\"\n",
    "    print(f\"Reading file from {data_path} ...\")\n",
    "    if not isinstance(data_path, str):\n",
    "        data_path = str(data_path)\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        if data_path.endswith('.txt') or data_path.endswith('.md'):\n",
    "            return [i.rstrip() for i in f.readlines()] # list\n",
    "        elif data_path.endswith('.json'):\n",
    "            return json.load(f) # dict\n",
    "        elif data_path.endswith('.jsonl'):\n",
    "            return [json.loads(i) for i in f.readlines()] # list\n",
    "        elif data_path.endswith('.yaml'):\n",
    "            return yaml.safe_load(f) # dict\n",
    "        else:\n",
    "            raise ValueError(f\"File extension [{data_path.split('.')[-1]}] not valid.\")\n",
    "        \n",
    "def write_file(data_path: str, data: list | dict) -> None:\n",
    "    # 检查文件路径是否以 '.txt' 结尾\n",
    "    if not os.path.exists(os.path.dirname(data_path)):\n",
    "        os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "    print(f\"Writing file to {data_path} ...\")\n",
    "    if not isinstance(data_path, str):\n",
    "        data_path = str(data_path)\n",
    "    if data_path.endswith('.txt'):\n",
    "        with open(data_path, 'w', encoding='utf-8') as f:\n",
    "            for i in data:\n",
    "                f.write(i + '\\n')\n",
    "    elif data_path.endswith('.json'):\n",
    "        with open(data_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    elif data_path.endswith('.jsonl'):\n",
    "        with open(data_path, 'w', encoding='utf-8') as f:\n",
    "            for i in data:\n",
    "                f.write(json.dumps(i, ensure_ascii=False) + '\\n')\n",
    "    else:\n",
    "        print(f'File extension [{data_path}] not valid.')\n",
    "        raise ValueError(f\"File extension [{data_path.split('.')[-1]}] not valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IDRR_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arg1', 'arg2', 'conn1', 'conn2', 'conn1sense1', 'conn1sense2',\n",
       "       'conn2sense1', 'conn2sense2', 'relation', 'split', 'Section',\n",
       "       'FileNumber', 'label11', 'label11id', 'label12', 'label12id', 'label21',\n",
       "       'label21id', 'label22', 'label22id', 'ans_word1', 'ans_word1id',\n",
       "       'ans_word2', 'ans_word2id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'/public/home/hongy/whsun/idrr/data/raw/pdtb2.p1.csv'\n",
    "df = IDRRDataFrames(\n",
    "    data_name='pdtb2',\n",
    "    data_level='top',\n",
    "    data_relation='Implicit',\n",
    "    data_path=data_path,\n",
    ")\n",
    "df.train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parquet格式化数据 (以qwen3为例)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdtb2_top_Implicit"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IDRR_data import IDRRDataFrames\n",
    "df = IDRRDataFrames(\n",
    "    data_name='pdtb2',\n",
    "    data_level='top',\n",
    "    data_relation='Implicit',\n",
    "    data_path=r'/data/whsun/idrr/data/raw/pdtb2.p1.csv',\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Task\\nYou are an expert in the field of implicit discourse relations. Your task is to determine the semantic-logical relationship between two given text segments and select the most appropriate relation label. Output only one of A, B, C, or D, and enclose it in \\\\boxed{{}}.\\n\\n### Relations\\n{relation_terms}\\n\\n### Segments\\nText segment 1: {arg1}\\nText segment 2: {arg2}\\n\\nYour answer:\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "prompt_template = read_txt(\"/data/whsun/idrr/prompts/rl_base.txt\")\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source': 'pdtb',\n",
       " 'prompt': [{'content': '<｜begin▁of▁sentence｜><｜User｜>### Task\\nYou are an expert in the field of implicit discourse relations. Your task is to determine the semantic-logical relationship between two given text segments and select the most appropriate relation label. Output only one of A, B, C, or D, and enclose it in \\\\boxed{}.\\n\\n### Relations\\nA. Comparison\\nB. Contingency\\nC. Expansion\\nD. Temporal\\n\\n### Segments\\nText segment 1: In an Oct. 19 review of \"The Misanthrope\" at Chicago\\'s Goodman Theatre (\"Revitalized Classics Take the Stage in Windy City,\" Leisure & Arts), the role of Celimene, played by Kim Cattrall, was mistakenly attributed to Christina Haag\\nText segment 2: Ms. Haag plays Elianti\\n\\nYour answer:\\n',\n",
       "   'role': 'user'}],\n",
       " 'reward_model': {'ground_truth': 'A'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/whsun/pretrained_models/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "\n",
    "def get_rl_data(data_source: str, df, label_list):\n",
    "    rl_data = []\n",
    "    relation_terms = '\\n'.join([f\"{chr(65 + i)}. {label}\" for i, label in enumerate(label_list)])\n",
    "    label2alpha = {label: chr(65 + i) for i, label in enumerate(label_list)}\n",
    "    for index, row in df.iterrows():\n",
    "        prompt = prompt_template.format(\n",
    "            relation_terms=relation_terms,\n",
    "            arg1=row['arg1'],\n",
    "            arg2=row['arg2'],\n",
    "        )\n",
    "        grounth_truth_alpha = label2alpha[row[\"label11\"]]\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "\n",
    "        rl_data.append(\n",
    "            {\n",
    "                \"data_source\": data_source,\n",
    "                \"prompt\": [{\"content\": prompt_text, \"role\": \"user\"}],\n",
    "                \"reward_model\": {\"ground_truth\": grounth_truth_alpha},\n",
    "            }\n",
    "        )\n",
    "    return Dataset.from_list(rl_data, split=\"train\")\n",
    "\n",
    "train_rl_dataset = get_rl_data(\"pdtb\", df.train_df, df.label_list)\n",
    "train_rl_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['data_source', 'prompt', 'reward_model'],\n",
       "     num_rows: 1183\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['data_source', 'prompt', 'reward_model'],\n",
       "     num_rows: 1046\n",
       " }))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_rl_dataset = get_rl_data(\"pdtb\", df.dev_df, df.label_list)\n",
    "test_rl_dataset = get_rl_data(\"pdtb\", df.test_df, df.label_list)\n",
    "dev_rl_dataset, test_rl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 13/13 [00:00<00:00, 512.68ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 949.80ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "703089"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/train.parquet\")\n",
    "# dev_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/dev.parquet\")\n",
    "test_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将label转化为关系定义进行sft\n",
    "1. 将二级label转为关系定义\n",
    "2. 模型1：论元对 -> 关系定义\n",
    "3. 模型2：模型1给出文本 -> label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Briefly describe the relationship between two arguments and output the final relation label.\\nArg1: {arg1}\\nArg2: {arg2}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "prompt_tmeplate = read_txt(\"/data/sunwh/idrr/prompts/arg2def.txt\")\n",
    "prompt_tmeplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /data/sunwh/idrr/data/arg2def/pdtb2/aplaca/train.json\n",
      "Data saved to /data/sunwh/idrr/data/arg2def/pdtb2/aplaca/test.json\n",
      "Data saved to /data/sunwh/idrr/data/arg2def/pdtb2/aplaca/dev.json\n"
     ]
    }
   ],
   "source": [
    "sense2df = {\n",
    "    \"Temporal\": \"The situations described in the arguments are related temporally.\",\n",
    "    \"Temporal.Asynchronous\": \"One envent is described as preceding the other.\",\n",
    "    \"Temporal.Synchrony\": \"There is some degree of temporal overlap between the events described by the arguments.\",\n",
    "    \"Contingency\": \"One of the situations described in Arg1 and Arg2 causally influences the other.\",\n",
    "    \"Contingency.Cause\":\"The situations described in the arguments are causally influenced and the two are not in a conditional relation.\",\n",
    "    \"Contingency.Pragmatic cause\":\"Arg1 expresses a claim and Arg2 provides justification for this claim.\",\n",
    "    \"Contingency.Condition\": \"The situation in Arg2 is taken to be the condition and the situation described in Arg1 is taken to be the consequence.\",\n",
    "    \"Contingency.Pragmatic condition\": \"Used for instances of conditional constructions whose interpretation deviates from that of the semantics of “Condition”.\",\n",
    "    \"Comparison\": \"A discourse relation is established between Arg1 and Arg2 in order to highlight prominent differences between the two situations.\",\n",
    "    \"Comparison.Contrast\": \"Arg1 and Arg2 share a predicate or property and a difference is highlighted with respect to the values assigned to the shared property.\",\n",
    "    \"Comparison.Pragmatic contrast\": \"A contrast between one of the arguments and an inference that can be drawn from the other, in many cases at the speech act level: The contrast is not between the situations described in Arg1 and Arg2.\",\n",
    "    \"Comparison.Concession\": \"One argument denotes a fact that triggers a set of potential consequences, while the other denies one or more of them.\",\n",
    "    \"Comparison.Pragmatic concession\": \"One argument denotes a fact that triggers a set of potential consequences, while the other denies one or more of them. The denial is not at the level of the situations described in Arg1 and Arg2, but rather at the level of inferences that can be drawn from them.\",\n",
    "    \"Expansion\": \"Expanding the discourse and move its narrative or exposition forward.\",\n",
    "    \"Expansion.Conjunction\":\"The situation described in Arg2 provides additional, discourse new, information that is related to the situation described in Arg1, but is not related to Arg1 in any of the ways described for other types of “EXPANSION”.\",\n",
    "    \"Expansion.Instantiation\":\"Arg1 evokes a set and Arg2 describes it in further detail, It may be a set of events, a set of reasons, or a generic set of events, behaviors, attitudes, etc.\",\n",
    "    \"Expansion.Restatement\":\"The semantics of Arg2 restates the semantics of Arg1. It is inferred that the situations described in Arg1 and Arg2 hold true at the same time.\",\n",
    "    \"Expansion.Alternative\":\"Two arguments denote alternative situations.\",\n",
    "    \"Expansion.Exception\":\"Arg2 specifies an exception to the generalization specified by Arg1. In other words, Arg1 is false because Arg2 is true, but if Arg2 were false, Arg1 would be true.\",\n",
    "    \"Expansion.List\":\"Arguments are members of a list, defined in the prior discourse.“List”does not require the situations specified in Arg1 and Arg2 to be directly related.\"\n",
    "}\n",
    "def write_json(file, data):\n",
    "    import json\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Data saved to {file}\")\n",
    "\n",
    "def write_alpaca_format(df, file_path):\n",
    "    alpaca_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = prompt_tmeplate.format(\n",
    "            arg1=row['arg1'],\n",
    "            arg2=row['arg2'],\n",
    "        )\n",
    "        sense = row['conn1sense1']\n",
    "        sense_lst = sense.split('.')\n",
    "        if len(sense_lst) > 1:\n",
    "            sense = '.'.join(sense_lst[:2])\n",
    "        alpaca_data.append(\n",
    "            {\n",
    "                \"instruction\": prompt,\n",
    "                \"input\": \"\",\n",
    "                \"output\": sense2df[sense] + f' Relation: {sense}' if len(df) > 9999 else sense,\n",
    "            }\n",
    "        )\n",
    "    write_json(file_path, alpaca_data)\n",
    "\n",
    "write_alpaca_format(df.train_df, \"/data/sunwh/idrr/data/arg2def/pdtb2/aplaca/train.json\")\n",
    "write_alpaca_format(df.test_df, \"/data/sunwh/idrr/data/arg2def/pdtb2/aplaca/test.json\")\n",
    "write_alpaca_format(df.dev_df, \"/data/sunwh/idrr/data/arg2def/pdtb2/aplaca/dev.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将easyr1的jsonl文件转为parquet格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_source': 'pdtb',\n",
       " 'prompt': [{'content': '<|im_start|>user\\n# Instruction\\nYou are an expert in the field of implicit discourse relation recognition. Your task is to analyze the implicit logical relation between two adjacent text segments and choose the most accurate relation from the options.\\n\\n# Input\\nSegment 1: In an Oct. 19 review of \"The Misanthrope\" at Chicago\\'s Goodman Theatre (\"Revitalized Classics Take the Stage in Windy City,\" Leisure & Arts), the role of Celimene, played by Kim Cattrall, was mistakenly attributed to Christina Haag\\nSegment 2: Ms. Haag plays Elianti\\nRelation option:\\nA. Comparison\\nB. Contingency\\nC. Expansion\\nD. Temporal<|im_end|>\\n<|im_start|>assistant\\n',\n",
       "   'role': 'user'}],\n",
       " 'reward_model': {'ground_truth': 'A'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    import json\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_rl_dataset(data_path):\n",
    "    data = read_jsonl(data_path)\n",
    "    rl_data = []\n",
    "    # data格式为problem, answer\n",
    "    from transformers import AutoTokenizer\n",
    "    from datasets import Dataset\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"/data/whsun/pretrained_models/Qwen/Qwen3-0.6B\")\n",
    "    data_source = \"pdtb\"\n",
    "    for item in data:\n",
    "        prompt_text = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"user\", \"content\": item['problem']}],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "        grounth_truth_alpha = item['answer'].strip()\n",
    "        rl_data.append(\n",
    "            {\n",
    "                \"data_source\": data_source,\n",
    "                \"prompt\": [{\"content\": prompt_text, \"role\": \"user\"}],\n",
    "                \"reward_model\": {\"ground_truth\": grounth_truth_alpha},\n",
    "            }\n",
    "        )\n",
    "    return Dataset.from_list(rl_data, split=\"train\")\n",
    "\n",
    "train_rl_dataset = write_rl_dataset(\"/data/whsun/idrr/data/rl/easyr1/pdtb2/top/sft_rl_train.jsonl\")\n",
    "test_rl_dataset = write_rl_dataset(\"/data/whsun/idrr/data/rl/easyr1/pdtb2/top/sft_rl_test.jsonl\")\n",
    "train_rl_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 13/13 [00:00<00:00, 86.21ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 645.72ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "640329"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/sft_rl_train.parquet\")\n",
    "test_rl_dataset.to_parquet(\"/data/whsun/idrr/data/rl/verl/pdtb2/top/sft_rl_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将parquet数据转成json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成！输出文件: /data/whsun/idrr/data/rl/verl/pdtb2/top/distill_qwen_1.5b_gen_test.json\n",
      "数据形状: (1046, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def parquet_to_json_pandas(input_file, output_file, orient='records', indent=2):\n",
    "    \"\"\"\n",
    "    使用pandas将Parquet转换为JSON\n",
    "    \n",
    "    参数:\n",
    "        input_file: 输入的Parquet文件路径\n",
    "        output_file: 输出的JSON文件路径\n",
    "        orient: JSON格式（'records'为行记录，'split'为分离格式等）\n",
    "        indent: JSON缩进，None为压缩格式，数字为缩进空格数\n",
    "    \"\"\"\n",
    "    # 读取Parquet文件\n",
    "    df = pd.read_parquet(input_file)\n",
    "    \n",
    "    # 转换为JSON字符串\n",
    "    json_str = df.to_json(orient=orient, indent=indent, force_ascii=False)\n",
    "    \n",
    "    # 写入文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(json_str)\n",
    "    \n",
    "    print(f\"转换完成！输出文件: {output_file}\")\n",
    "    print(f\"数据形状: {df.shape}\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    parquet_to_json_pandas('/data/whsun/idrr/data/rl/verl/pdtb2/top/distill_qwen_1.5b_gen_test.parquet', '/data/whsun/idrr/data/rl/verl/pdtb2/top/distill_qwen_1.5b_gen_test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据lmf输出构造alpaca训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9485/12632 = 0.7509\n",
      "Total samples: 9485\n",
      "Correct samples: 9485\n",
      "Data saved to /data/whsun/idrr/data/sft/rl_cold_start/pdtb2/top/alpaca/qwen3-8b-exp-dapo_lora-distill_train.json\n"
     ]
    }
   ],
   "source": [
    "data = read_file('/data/whsun/idrr/results/rl_cold_start/pdtb2/top/Qwen3-8B-E1_by_qwen3_max-DAPO-lora/global_step_210/train/generated_predictions.jsonl')\n",
    "new_data = []\n",
    "import re\n",
    "def re_search(text, type):\n",
    "    '''\n",
    "    搜索text中符合type类型的内容,\n",
    "    如果text中存在多个符合type类型的内容，则返回最后一个\n",
    "    如果搜索不到，则抛出异常\n",
    "    '''\n",
    "    pattern = ''\n",
    "    flags = re.DOTALL  # 添加 DOTALL 标志，让 . 也匹配换行符\n",
    "    \n",
    "    if type == 'json':\n",
    "        pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    elif type == 'box':\n",
    "        pattern = r'boxed{(.*?)}'\n",
    "    elif type == 'xml':\n",
    "        pattern = r'```xml\\s*(.*?)\\s*```'\n",
    "\n",
    "    matches = re.findall(pattern, text, flags)\n",
    "    if not matches and type == 'json':\n",
    "        # 使用贪婪匹配来匹配完整的字典结构\n",
    "        pattern = r'\\{.*\\}'\n",
    "        matches = re.findall(pattern, text, flags)\n",
    "\n",
    "    if len(matches) > 1:\n",
    "        logger.warning(f\"the number of matches is greater than 1:\")\n",
    "        for i, match in enumerate(matches):\n",
    "            logger.debug(f\"match{i}:\\n{match}\\n\")\n",
    "    elif not matches:\n",
    "        logger.error(f\"no matches found for {type} in text:\\n{text}\\n\")\n",
    "        raise ValueError()\n",
    "        return text\n",
    "\n",
    "    structured_text = matches[-1]\n",
    "    # if type == 'json':\n",
    "    #     structured_text = repair_json(structured_text)\n",
    "    return structured_text\n",
    "\n",
    "\n",
    "correct_cnt = 0\n",
    "for item in data:\n",
    "    pred = re_search(item['predict'], 'box')\n",
    "    label = re_search(item['label'], 'box')\n",
    "    # print(f\"Predicted: {pred}, Label: {label}\")\n",
    "    if pred == label:\n",
    "        correct_cnt += 1\n",
    "        new_data.append({\n",
    "                'instruction': item['prompt'].replace('\\nassistant\\n', '').replace('user\\n', ''),\n",
    "                'input': '',\n",
    "                'output': item['predict'],\n",
    "            })\n",
    "        \n",
    "print(f\"Accuracy: {correct_cnt}/{len(data)} = {correct_cnt/len(data):.4f}\")\n",
    "print(f\"Total samples: {len(new_data)}\")\n",
    "print(f\"Correct samples: {correct_cnt}\")\n",
    "write_json('/data/whsun/idrr/data/sft/rl_cold_start/pdtb2/top/alpaca/qwen3-8b-exp-dapo_lora-distill_train.json', new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 根据vllm_offline_infer输出json构造alpaca训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file from /public/home/hongy/whsun/idrr/results/pdtb2/top/qwen3_8b_dapo_lora/rl_train_gen.json ...\n",
      "Accuracy: 8089/12632 = 0.6404\n",
      "Total samples: 8089\n",
      "Correct samples: 8089\n",
      "Writing file to /public/home/hongy/whsun/idrr/data/sft/rl_cold_start/pdtb2/top/alpaca/qwen3_8b_dapo_lora_train.json ...\n"
     ]
    }
   ],
   "source": [
    "data = read_file('/public/home/hongy/whsun/idrr/results/pdtb2/top/qwen3_8b_dapo_lora/rl_train_gen.json')\n",
    "new_data = []\n",
    "import re\n",
    "def re_search(text, type):\n",
    "    '''\n",
    "    搜索text中符合type类型的内容,\n",
    "    如果text中存在多个符合type类型的内容，则返回最后一个\n",
    "    如果搜索不到，则抛出异常\n",
    "    '''\n",
    "    pattern = ''\n",
    "    flags = re.DOTALL  # 添加 DOTALL 标志，让 . 也匹配换行符\n",
    "    \n",
    "    if type == 'json':\n",
    "        pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    elif type == 'box':\n",
    "        pattern = r'boxed{(.*?)}'\n",
    "    elif type == 'xml':\n",
    "        pattern = r'```xml\\s*(.*?)\\s*```'\n",
    "\n",
    "    matches = re.findall(pattern, text, flags)\n",
    "    if not matches and type == 'json':\n",
    "        # 使用贪婪匹配来匹配完整的字典结构\n",
    "        pattern = r'\\{.*\\}'\n",
    "        matches = re.findall(pattern, text, flags)\n",
    "\n",
    "    if len(matches) > 1:\n",
    "        print(f\"the number of matches is greater than 1:\")\n",
    "        for i, match in enumerate(matches):\n",
    "            print(f\"match{i}:\\n{match}\\n\")\n",
    "    elif not matches:\n",
    "        print(f\"no matches found for {type} in text:\\n{text}\\n\")\n",
    "        raise ValueError()\n",
    "        return text\n",
    "\n",
    "    structured_text = matches[-1]\n",
    "    # if type == 'json':\n",
    "    #     structured_text = repair_json(structured_text)\n",
    "    return structured_text\n",
    "\n",
    "\n",
    "correct_cnt = 0\n",
    "for item in data:\n",
    "    pred = re_search(item['output_text'], 'box')\n",
    "    label = item['meta']['label']\n",
    "    if pred == label:\n",
    "        correct_cnt += 1\n",
    "        new_data.append({\n",
    "                'instruction': item['prompt'].replace('<|im_start|>user\\n', '').replace('<|im_end|>\\n<|im_start|>assistant\\n', ''),\n",
    "                'input': '',\n",
    "                'output': item['output_text'],\n",
    "            })\n",
    "        \n",
    "print(f\"Accuracy: {correct_cnt}/{len(data)} = {correct_cnt/len(data):.4f}\")\n",
    "print(f\"Total samples: {len(new_data)}\")\n",
    "print(f\"Correct samples: {correct_cnt}\")\n",
    "write_file('/public/home/hongy/whsun/idrr/data/sft/rl_cold_start/pdtb2/top/alpaca/qwen3_8b_dapo_lora_train.json', new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whsun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
